{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import slim_conservation_scoring.seqtools.general_utils as tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import slim_conservation_scoring.pipeline.group_conservation_objects as group_tools\n",
    "import pairk\n",
    "from pathlib import Path\n",
    "from Bio import AlignIO, Seq, SeqIO, Align\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from slim_conservation_scoring.seqtools import pssms\n",
    "import logomaker as lm\n",
    "from ast import literal_eval\n",
    "import slim_conservation_scoring.conservation_scores.tools.pairwise_tools as pairwise_tools\n",
    "import slim_conservation_scoring.conservation_scores.tools.score_plots as score_plots\n",
    "import slim_conservation_scoring.conservation_scores.tools.basic_plotting as basic_plots\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('custom_standard')\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def convert_jsonfile_to_relative(json_file):\n",
    "    return json_file.replace(\"/home/jch/Documents/08-benchmark/\", \"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_weights = {\n",
    "    \"DOC_WW_Pin1_4\": np.array([0, 0, 0, 1, 1, 0]),  # ...([ST])P.\n",
    "    \"LIG_AP2alpha_2\": np.array([1, 1, 1]),  # DP[FW]\n",
    "    \"LIG_EH_1\": np.array([0, 1, 1, 1, 0]),  # .NPF.\n",
    "    \"LIG_SH2_GRB2like\": np.array([1, 1, 1, 0]),  # (Y)([EDST]|[MLIVAFYHQW])N.\n",
    "    \"LIG_SH3_CIN85_PxpxPR_1\": np.array([1, 0, 1, 0, 1, 1]),  # P.[AP].PR\n",
    "    \"enah_LPPPP_FPPPP\": np.array([2, 1, 0, 1, 1]),  # [FWYL]P.[AFILTVYWP]P\n",
    "    \"TRAF6\": np.array([0, 0, 0, 1, 0, 1, 0, 0, 1]),  # ...P.E..[FYWDE]\n",
    "}\n",
    "\n",
    "table_file = (\n",
    "    \"../../benchmark/benchmark_v4/p3_conservation/benchmark_table_ANNOTATED.csv\"\n",
    ")\n",
    "df = pd.read_csv(table_file)\n",
    "df = df[\n",
    "    df[\"ELM_motif_class\"] != \"LIG_14-3-3_CanoR_1\"\n",
    "]  # this motif has a variable length regex and so it's more difficult to apply any position weighting\n",
    "df = df[\n",
    "    [\n",
    "        \"reference_index\",\n",
    "        \"ELM_motif_class\",\n",
    "        \"Organism\",\n",
    "        \"UniprotID\",\n",
    "        \"regex\",\n",
    "        \"hit_sequence\",\n",
    "        \"gene_id\",\n",
    "        \"hit start position\",\n",
    "        \"hit end position\",\n",
    "        \"verified interaction\",\n",
    "        \"name\",\n",
    "        \"json_file\",\n",
    "        \"critical_error\",\n",
    "    ]\n",
    "]\n",
    "df = df[df[\"critical_error\"].isna()]\n",
    "df[\"json_file\"] = df[\"json_file\"].apply(convert_jsonfile_to_relative)\n",
    "df[\"weight_array\"] = df[\"ELM_motif_class\"].map(position_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def json_2_z_score_list(json_file, level, scorekey):\n",
    "    og = group_tools.ConserGene(\n",
    "        json_file, filepath_converter=convert_jsonfile_to_relative\n",
    "    )\n",
    "    if level not in og.levels_passing_filters:\n",
    "        return\n",
    "    lvlo = og.get_level_obj(level, filepath_converter=convert_jsonfile_to_relative)\n",
    "    if scorekey not in lvlo.conservation_scores:\n",
    "        return\n",
    "    if \"hit_z_scores\" not in lvlo.conservation_scores[scorekey]:\n",
    "        return\n",
    "    return lvlo.conservation_scores[scorekey][\"hit_z_scores\"]\n",
    "\n",
    "def add_scorelist_2_df(df, level, scorekey):\n",
    "    colname = f\"{level}_{scorekey}_z_scores\"\n",
    "    df[colname] = df[\"json_file\"].apply(\n",
    "        lambda x: json_2_z_score_list(x, level, scorekey)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import asdict, define, field, validators\n",
    "\n",
    "\n",
    "@define\n",
    "class PairwiseScoreResults:\n",
    "    flanked_hit: str\n",
    "    flanked_hit_start_position_in_idr: int\n",
    "    original_hit_st_in_flanked_hit: int\n",
    "    original_hit_end_in_flanked_hit: int\n",
    "    function_name: str\n",
    "    function_params: dict\n",
    "    lflank: int\n",
    "    rflank: int\n",
    "    kmer_aln_file: str | Path\n",
    "    flanked_hit_sequence: str\n",
    "    flanked_hit_scores: list\n",
    "    flanked_hit_z_scores: list\n",
    "    hit_sequence: str\n",
    "    hit_scores: list\n",
    "    hit_z_scores: list\n",
    "    pairk_conservation_params: dict\n",
    "    bg_std: float\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        self.kmer_aln_file = convert_jsonfile_to_relative(self.kmer_aln_file)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AlnScoreResults:\n",
    "    file: str\n",
    "    function_name: str\n",
    "    function_params: dict\n",
    "    hit_scores: list\n",
    "    hit_z_scores: list\n",
    "\n",
    "\n",
    "def slice_aln_scores(lvlo: group_tools.LevelAlnScore, aln_start, aln_end):\n",
    "    hit_slice = slice(aln_start, aln_end + 1)\n",
    "    hit_scores = lvlo.scores[hit_slice]\n",
    "    hit_z_scores = lvlo.z_scores[hit_slice]\n",
    "    hit_aln_seq = lvlo.query_aln_sequence[hit_slice]\n",
    "    return hit_scores, hit_z_scores, hit_aln_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2logoplot_alnscore(\n",
    "    jsonfile, score_key, with_gaps=False, axes=None, level=\"Vertebrata\", flank=5\n",
    "):\n",
    "    og = group_tools.ConserGene(\n",
    "        jsonfile, filepath_converter=convert_jsonfile_to_relative\n",
    "    )\n",
    "    lvlo = og.get_aln_score_obj(\n",
    "        level, score_key, filepath_converter=convert_jsonfile_to_relative\n",
    "    )\n",
    "    flst, flend, flhit = tools.pad_hit(\n",
    "        og.query_idr_sequence,\n",
    "        og.hit_st_in_idr,\n",
    "        og.hit_end_in_idr,\n",
    "        l_flank=flank,\n",
    "        r_flank=flank,\n",
    "    )\n",
    "    query_idr, index = tools.reindex_alignment_str(\n",
    "        lvlo.query_aln_sequence[lvlo.idr_aln_start : lvlo.idr_aln_end + 1]\n",
    "    )\n",
    "    flstaln, flendaln = index[flst], index[flend]\n",
    "    flanked_hit_scores, flanked_hit_z_scores, flhit_aln_seq = slice_aln_scores(\n",
    "        lvlo, flstaln + lvlo.idr_aln_start, flendaln + lvlo.idr_aln_start\n",
    "    )\n",
    "    idr_aln = lvlo.aln[:, lvlo.idr_aln_start : lvlo.idr_aln_end + 1]\n",
    "    flhit_aln = idr_aln[:, flstaln : flendaln + 1]\n",
    "\n",
    "    if not with_gaps:\n",
    "        seqlist, query_slice, nongapinds = score_plots.strip_gaps_from_slice(\n",
    "            flhit_aln, flhit_aln_seq\n",
    "        )\n",
    "        score_list = list(np.array(flanked_hit_z_scores)[nongapinds])\n",
    "    else:\n",
    "        seqlist = [str(i.seq) for i in list(flhit_aln)]\n",
    "        query_slice = flhit_aln_seq\n",
    "        score_list = flanked_hit_z_scores\n",
    "    if axes is None:\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 4))\n",
    "    basic_plots.plot_score_bar_plot(\n",
    "        ax=axes[0],\n",
    "        score_list=score_list,\n",
    "        query_seq=query_slice,\n",
    "    )\n",
    "    basic_plots.plot_logo(\n",
    "        ax=axes[1],\n",
    "        str_list=seqlist,\n",
    "        tick_label_str=query_slice,\n",
    "    )\n",
    "    counts = pssms.alignment_2_counts(seqlist, show_plot=False, heatmap=False)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2logoplot(\n",
    "    jsonfile, score_key, axes=None, level=\"Vertebrata\"\n",
    "):\n",
    "    og = group_tools.ConserGene(\n",
    "        jsonfile, filepath_converter=convert_jsonfile_to_relative\n",
    "    )\n",
    "    lvlo = og.get_level_obj(level, filepath_converter=convert_jsonfile_to_relative)\n",
    "    result = PairwiseScoreResults(**lvlo.conservation_scores[score_key])\n",
    "    mat_res = pairk.PairkAln.from_file(result.kmer_aln_file)\n",
    "    subseqdf = mat_res.orthokmer_matrix.copy()\n",
    "    seqlist = subseqdf.loc[result.flanked_hit_start_position_in_idr].to_list()\n",
    "    if axes is None:\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 4))\n",
    "    basic_plots.plot_score_bar_plot(\n",
    "        ax=axes[0],\n",
    "        score_list=result.flanked_hit_z_scores,\n",
    "        query_seq=result.flanked_hit_sequence,\n",
    "    )\n",
    "    basic_plots.plot_logo(\n",
    "        ax=axes[1], str_list=seqlist, tick_label_str=result.flanked_hit_sequence\n",
    "    )\n",
    "    counts = pssms.alignment_2_counts(seqlist, show_plot=False, heatmap=False)\n",
    "    return counts, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_plot(s, level, pairkey = \"pairk_aln_lf5_rf5_edssmat50\", flank=5):\n",
    "    jsonfile = s[\"json_file\"]\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(20, 4))\n",
    "    _ = json2logoplot_alnscore(\n",
    "        jsonfile,\n",
    "        \"aln_property_entropy\",\n",
    "        axes=ax[:, 0],\n",
    "        level=level,\n",
    "        with_gaps=True,\n",
    "        flank=flank,\n",
    "    )\n",
    "    # automatically uses whatever scoring parameters are in the json files (should be just normal right now)\n",
    "    _ = json2logoplot_alnscore(\n",
    "        jsonfile,\n",
    "        \"aln_property_entropy\",\n",
    "        axes=ax[:, 1],\n",
    "        level=level,\n",
    "        with_gaps=False,\n",
    "        flank=flank,\n",
    "    )\n",
    "    _ = json2logoplot(\n",
    "        jsonfile,\n",
    "        pairkey,\n",
    "        axes=ax[:, 2],\n",
    "        level=level,\n",
    "    )\n",
    "    for axi in ax[0, :]:\n",
    "        axi.set_ylim([-4, 4])\n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the hits to make logos for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = Path(\"logos\")\n",
    "OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "instances = [\n",
    "    (\"9606_0:00294e\", 553, \"Vertebrata\", {}),\n",
    "    (\"9606_0:000643\", 266, \"Metazoa\", {}),\n",
    "    (\"9606_0:000fe9\", 1377, \"Metazoa\", {}),\n",
    "    (\"9606_0:003dd5\", 1241, \"Vertebrata\", dict(pairkey=\"pairk_aln_lf0_rf0_edssmat50\", flank=0)),\n",
    "]\n",
    "for i in instances:\n",
    "    temp = df[(df[\"gene_id\"] == i[0]) & (df[\"hit start position\"] == i[1])].copy()\n",
    "    assert len(temp) == 1\n",
    "    temp = temp.iloc[0]\n",
    "    fig, ax = composite_plot(temp, i[2], **i[3])\n",
    "    filename = f\"{temp['reference_index']}-{temp['name']}-{temp['UniprotID']}-{i[2]}-{temp['gene_id'].replace(':','-')}.png\"\n",
    "    fig.savefig(\n",
    "        OUTPUT_FOLDER / filename,\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = Path(\"../figure4/logos/\")\n",
    "OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "instances = [\n",
    "    (\"9606_0:000b76\", 1201, \"Vertebrata\"),\n",
    "    (\"9606_0:000b76\", 1201, \"Metazoa\"),\n",
    "]\n",
    "for i in instances:\n",
    "    temp = df[(df[\"gene_id\"] == i[0]) & (df[\"hit start position\"] == i[1])].copy()\n",
    "    assert len(temp) == 1\n",
    "    temp = temp.iloc[0]\n",
    "    fig, ax = composite_plot(temp, i[2])\n",
    "    filename = f\"{temp['reference_index']}-{temp['name']}-{temp['UniprotID']}-{i[2]}-{temp['gene_id'].replace(':','-')}.png\"\n",
    "    fig.savefig(\n",
    "        OUTPUT_FOLDER / filename,\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "odb_conservation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
